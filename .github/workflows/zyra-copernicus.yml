name: Zyra Copernicus Acquire

on:
  workflow_dispatch:
    inputs:
      DATASET_NAME:
        description: Dataset name (e.g., copernicus)
        required: true
        type: string

env:
  ZYRA_SCHEDULER_IMAGE: ghcr.io/noaa-gsl/zyra-scheduler:latest

jobs:
  acquire-copernicus:
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/noaa-gsl/zyra-scheduler:latest
      options: >-
        --entrypoint ""
        --user 0
    env:
      COPERNICUS_USERNAME: ${{ secrets.COPERNICUS_USERNAME }}
      COPERNICUS_PASSWORD: ${{ secrets.COPERNICUS_PASSWORD }}

    steps:
      - uses: actions/checkout@v4

      - name: Install dependencies
        run: pip install --no-cache-dir 'zyra[datatransfer]' requests
      
      - name: Acquire imagery via Copernicus Data Space (OAuth2 + STAC v1)
        run: |
          python3 <<'PYCODE'
          import os, requests, json
          from datetime import datetime, timedelta
      
          # --- Auth variables from GitHub secrets ---
          CLIENT_ID = os.environ["CDSE_CLIENT_ID"]
          CLIENT_SECRET = os.environ["CDSE_CLIENT_SECRET"]
      
          # --- 1. Get OAuth2 token ---
          TOKEN_URL = "https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token"
          print("Requesting access token...")
          token_resp = requests.post(
              TOKEN_URL,
              data={
                  "grant_type": "client_credentials",
                  "client_id": CLIENT_ID,
                  "client_secret": CLIENT_SECRET,
              },
              timeout=60,
          )
          token_resp.raise_for_status()
          token = token_resp.json()["access_token"]
          headers = {"Authorization": f"Bearer {token}"}
      
          # --- 2. Define search parameters ---
          # Use STAC v1 endpoint
          STAC_URL = "https://stac.dataspace.copernicus.eu/v1/collections/SENTINEL-2/items"
      
          # Last 30 days, area over northern Italy (guaranteed data)
          end = datetime.utcnow() - timedelta(days=30)
          start = datetime.utcnow() - timedelta(days=60)
          datetime_range = f"{start.strftime('%Y-%m-%dT%H:%M:%SZ')}/{end.strftime('%Y-%m-%dT%H:%M:%SZ')}"
      
          bbox = [5.0, 45.0, 20.0, 63.0]  # Broader Northern Italy region
          params = {
              "bbox": ",".join(map(str, bbox)),
              "datetime": datetime_range,
              "limit": 5  # Limit to 5 results for a quick test
          }
      
          print("Querying STAC endpoint...")
          resp = requests.get(STAC_URL, headers=headers, params=params, timeout=120)
          if resp.status_code == 403:
              print("❌ Forbidden: Check your client permissions for Catalogue API.")
              print(resp.text)
              exit(1)
          resp.raise_for_status()
          data = resp.json()
      
          features = data.get("features", [])
          print(f"Found {len(features)} results")
      
          outdir = f"_work/images/{os.environ.get('DATASET_NAME', 'copernicus')}"
          os.makedirs(outdir, exist_ok=True)
      
          for f in features:
              title = f.get("id", "unknown")
              assets = f.get("assets", {})
              if not assets:
                  print(f"⚠️ No downloadable assets for {title}")
                  continue
              # Choose the first available asset (often 'data' or 'thumbnail')
              asset_key = next(iter(assets))
              url = assets[asset_key]["href"]
              print(f"⬇️  Downloading {title} ({asset_key})")
              r2 = requests.get(url, headers=headers, stream=True, timeout=600)
              if r2.status_code != 200:
                  print(f"⚠️ Skipping {title}, HTTP {r2.status_code}")
                  continue
              dest = os.path.join(outdir, f"{title}.zip")
              with open(dest, "wb") as fz:
                  for chunk in r2.iter_content(chunk_size=8192):
                      fz.write(chunk)
          print("✅ Acquisition complete.")
          PYCODE
        env:
          CDSE_CLIENT_ID: ${{ secrets.CDSE_CLIENT_ID }}
          CDSE_CLIENT_SECRET: ${{ secrets.CDSE_CLIENT_SECRET }}
          DATASET_NAME: ${{ inputs.DATASET_NAME || 'copernicus' }}


      - name: Upload imagery artifacts
        uses: actions/upload-artifact@v4
        with:
          name: copernicus-${{ inputs.DATASET_NAME }}
          path: _work/images/${{ inputs.DATASET_NAME }}
