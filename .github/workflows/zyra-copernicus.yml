name: Zyra Copernicus Acquire

on:
  workflow_dispatch:
    inputs:
      DATASET_NAME:
        description: Dataset name (e.g., copernicus)
        required: true
        type: string

env:
  ZYRA_SCHEDULER_IMAGE: ghcr.io/noaa-gsl/zyra-scheduler:latest

jobs:
  acquire-copernicus:
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/noaa-gsl/zyra-scheduler:latest
      options: >-
        --entrypoint ""
        --user 0
    env:
      COPERNICUS_USERNAME: ${{ secrets.COPERNICUS_USERNAME }}
      COPERNICUS_PASSWORD: ${{ secrets.COPERNICUS_PASSWORD }}

    steps:
      - uses: actions/checkout@v4

      - name: Install dependencies
        run: pip install --no-cache-dir 'zyra[datatransfer]' requests
      
      - name: Acquire imagery via CDSE STAC API
        run: |
          python3 <<'PYCODE'
          import os, requests, json
          from datetime import datetime, timedelta
      
          USER = os.environ["COPERNICUS_USERNAME"]
          PASS = os.environ["COPERNICUS_PASSWORD"]
      
          # Use STAC API endpoint
          base = "https://catalogue.dataspace.copernicus.eu/stac/collections/SENTINEL-1/items"
          
          # Time window
          end = datetime.utcnow()
          start = end - timedelta(hours=8)
          dt = f"{start.isoformat()}Z/{end.isoformat()}Z"
          
          # Example boundingâ€box (xmin,ymin,xmax,ymax)
          bbox = [-120.0, 35.0, -118.0, 37.0]
      
          params = {
              "bbox": ",".join(map(str, bbox)),
              "datetime": dt,
              "limit": "3"
          }
      
          resp = requests.get(base, auth=(USER, PASS), params=params, timeout=120)
          resp.raise_for_status()
          data = resp.json()
      
          items = data.get("features", [])
          print(f"Found {len(items)} items")
          os.makedirs(f"_work/images/{os.environ['DATASET_NAME']}", exist_ok=True)
      
          for it in items:
              asset = it["assets"].get("data") or next(iter(it["assets"].values()))
              url = asset["href"]
              name = it["id"] + ".zip"
              print(f"Downloading {name}")
              with requests.get(url, auth=(USER, PASS), stream=True) as r2:
                  r2.raise_for_status()
                  with open(f"_work/images/{os.environ['DATASET_NAME']}/{name}", "wb") as f:
                      for chunk in r2.iter_content(chunk_size=8192):
                          f.write(chunk)
          PYCODE
        env:
          COPERNICUS_USERNAME: ${{ secrets.COPERNICUS_USERNAME }}
          COPERNICUS_PASSWORD: ${{ secrets.COPERNICUS_PASSWORD }}
          DATASET_NAME: ${{ inputs.DATASET_NAME }}






      - name: Upload imagery artifacts
        uses: actions/upload-artifact@v4
        with:
          name: copernicus-${{ inputs.DATASET_NAME }}
          path: _work/images/${{ inputs.DATASET_NAME }}
